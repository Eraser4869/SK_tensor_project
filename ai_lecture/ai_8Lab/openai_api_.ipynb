{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac0c362c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-dotenv\n",
      "  Downloading python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\n",
      "Downloading python_dotenv-1.1.1-py3-none-any.whl (20 kB)\n",
      "Installing collected packages: python-dotenv\n",
      "Successfully installed python-dotenv-1.1.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b1e29e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "\n",
    "# print('key:', OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c00b6fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai\n",
      "  Downloading openai-1.91.0-py3-none-any.whl.metadata (26 kB)\n",
      "Collecting anyio<5,>=3.5.0 (from openai)\n",
      "  Downloading anyio-4.9.0-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting distro<2,>=1.7.0 (from openai)\n",
      "  Downloading distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting httpx<1,>=0.23.0 (from openai)\n",
      "  Downloading httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting jiter<1,>=0.4.0 (from openai)\n",
      "  Downloading jiter-0.10.0-cp39-cp39-win_amd64.whl.metadata (5.3 kB)\n",
      "Collecting pydantic<3,>=1.9.0 (from openai)\n",
      "  Downloading pydantic-2.11.7-py3-none-any.whl.metadata (67 kB)\n",
      "Collecting sniffio (from openai)\n",
      "  Using cached sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting tqdm>4 (from openai)\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\project\\sk_tensor_project\\.venv\\lib\\site-packages (from openai) (4.14.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\project\\sk_tensor_project\\.venv\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (1.3.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\project\\sk_tensor_project\\.venv\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: certifi in c:\\project\\sk_tensor_project\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2025.6.15)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
      "  Downloading httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting h11>=0.16 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
      "  Using cached h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3,>=1.9.0->openai)\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.33.2 (from pydantic<3,>=1.9.0->openai)\n",
      "  Downloading pydantic_core-2.33.2-cp39-cp39-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting typing-inspection>=0.4.0 (from pydantic<3,>=1.9.0->openai)\n",
      "  Downloading typing_inspection-0.4.1-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: colorama in c:\\project\\sk_tensor_project\\.venv\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n",
      "Downloading openai-1.91.0-py3-none-any.whl (735 kB)\n",
      "   ---------------------------------------- 0.0/735.8 kB ? eta -:--:--\n",
      "   --------------------------------------- 735.8/735.8 kB 10.1 MB/s eta 0:00:00\n",
      "Downloading anyio-4.9.0-py3-none-any.whl (100 kB)\n",
      "Downloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Downloading httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Downloading httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
      "Downloading jiter-0.10.0-cp39-cp39-win_amd64.whl (208 kB)\n",
      "Downloading pydantic-2.11.7-py3-none-any.whl (444 kB)\n",
      "Downloading pydantic_core-2.33.2-cp39-cp39-win_amd64.whl (2.0 MB)\n",
      "   ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.0/2.0 MB 10.9 MB/s eta 0:00:00\n",
      "Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Using cached h11-0.16.0-py3-none-any.whl (37 kB)\n",
      "Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Downloading typing_inspection-0.4.1-py3-none-any.whl (14 kB)\n",
      "Installing collected packages: typing-inspection, tqdm, sniffio, pydantic-core, jiter, h11, distro, annotated-types, pydantic, httpcore, anyio, httpx, openai\n",
      "\n",
      "   --- ------------------------------------  1/13 [tqdm]\n",
      "   --- ------------------------------------  1/13 [tqdm]\n",
      "   --- ------------------------------------  1/13 [tqdm]\n",
      "   --- ------------------------------------  1/13 [tqdm]\n",
      "   --- ------------------------------------  1/13 [tqdm]\n",
      "   --- ------------------------------------  1/13 [tqdm]\n",
      "   --- ------------------------------------  1/13 [tqdm]\n",
      "   --------- ------------------------------  3/13 [pydantic-core]\n",
      "   --------------- ------------------------  5/13 [h11]\n",
      "   --------------- ------------------------  5/13 [h11]\n",
      "   --------------- ------------------------  5/13 [h11]\n",
      "   ------------------ ---------------------  6/13 [distro]\n",
      "   ------------------ ---------------------  6/13 [distro]\n",
      "   --------------------- ------------------  7/13 [annotated-types]\n",
      "   ------------------------ ---------------  8/13 [pydantic]\n",
      "   ------------------------ ---------------  8/13 [pydantic]\n",
      "   ------------------------ ---------------  8/13 [pydantic]\n",
      "   ------------------------ ---------------  8/13 [pydantic]\n",
      "   ------------------------ ---------------  8/13 [pydantic]\n",
      "   ------------------------ ---------------  8/13 [pydantic]\n",
      "   ------------------------ ---------------  8/13 [pydantic]\n",
      "   ------------------------ ---------------  8/13 [pydantic]\n",
      "   ------------------------ ---------------  8/13 [pydantic]\n",
      "   ------------------------ ---------------  8/13 [pydantic]\n",
      "   ------------------------ ---------------  8/13 [pydantic]\n",
      "   ------------------------ ---------------  8/13 [pydantic]\n",
      "   ------------------------ ---------------  8/13 [pydantic]\n",
      "   ------------------------ ---------------  8/13 [pydantic]\n",
      "   ------------------------ ---------------  8/13 [pydantic]\n",
      "   ------------------------ ---------------  8/13 [pydantic]\n",
      "   ------------------------ ---------------  8/13 [pydantic]\n",
      "   ------------------------ ---------------  8/13 [pydantic]\n",
      "   ------------------------ ---------------  8/13 [pydantic]\n",
      "   ------------------------ ---------------  8/13 [pydantic]\n",
      "   --------------------------- ------------  9/13 [httpcore]\n",
      "   --------------------------- ------------  9/13 [httpcore]\n",
      "   --------------------------- ------------  9/13 [httpcore]\n",
      "   --------------------------- ------------  9/13 [httpcore]\n",
      "   --------------------------- ------------  9/13 [httpcore]\n",
      "   --------------------------- ------------  9/13 [httpcore]\n",
      "   ------------------------------ --------- 10/13 [anyio]\n",
      "   ------------------------------ --------- 10/13 [anyio]\n",
      "   ------------------------------ --------- 10/13 [anyio]\n",
      "   ------------------------------ --------- 10/13 [anyio]\n",
      "   ------------------------------ --------- 10/13 [anyio]\n",
      "   ------------------------------ --------- 10/13 [anyio]\n",
      "   ------------------------------ --------- 10/13 [anyio]\n",
      "   --------------------------------- ------ 11/13 [httpx]\n",
      "   --------------------------------- ------ 11/13 [httpx]\n",
      "   --------------------------------- ------ 11/13 [httpx]\n",
      "   --------------------------------- ------ 11/13 [httpx]\n",
      "   --------------------------------- ------ 11/13 [httpx]\n",
      "   --------------------------------- ------ 11/13 [httpx]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ---------------------------------------- 13/13 [openai]\n",
      "\n",
      "Successfully installed annotated-types-0.7.0 anyio-4.9.0 distro-1.9.0 h11-0.16.0 httpcore-1.0.9 httpx-0.28.1 jiter-0.10.0 openai-1.91.0 pydantic-2.11.7 pydantic-core-2.33.2 sniffio-1.3.1 tqdm-4.67.1 typing-inspection-0.4.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7bd9c36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "\n",
    "response = client.responses.create(\n",
    "    model='gpt-4.1',\n",
    "    input='스타워즈 시리즈의 다스베이더 역할에 대해 한줄로 설명해줘'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0d725eb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'다스 베이더는 스타워즈 시리즈에서 제다이 기사에서 시스 군주로 변한 아나킨 스카이워커를 연기한 악역 캐릭터입니다.'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.output_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5930703e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "다스 베이더는 젊은 제다이였던 아나킨 스카이워커가 어둠의 포스에 굴복해 은하 제국의 상징적인 악역이 된 인물이다.\n"
     ]
    }
   ],
   "source": [
    "response = client.responses.create(\n",
    "\n",
    "    model='gpt-4.1',\n",
    "    instructions='당신은 영화 평론가입니다.',\n",
    "    input='스타워즈 시리즈의 다스베이더 역할에 대해 한줄로 설명해줘'\n",
    ")\n",
    "\n",
    "print(response.output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "127f10a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "물론이야! \"파프니르\"는 북유럽 신화에 등장하는 강력한 드래곤이자 탐욕의 상징이지. 그와 관련한 검사 캐릭터와 고유 능력을 다음과 같이 설정해볼게:\n",
      "\n",
      "---\n",
      "\n",
      "### 캐릭터 이름  \n",
      "**에이라 슈타인발트** (Eira Steinvalt)\n",
      "\n",
      "### 배경  \n",
      "옛 전쟁의 불씨가 잠깐 식었을 무렵, 에이라는 한 마을의 평범한 대장장이 집안에서 태어났다. 어느 날, 마을 근처의 동굴에서 발견한 청동색의 이빨 모양 광석을 우연히 집으로 들여오게 된다. 그러나 그것은 파프니르의 비늘에서 파생된 광석이었고, 그녀는 그 잔재에서 뿜어져 나오는 저주와 동시에 힘을 얻게 된다.\n",
      "\n",
      "### 성격  \n",
      "겉으론 평온해 보이나, 내면에는 욕망과 분노가 불타고 있다. 그럼에도 불구하고 스스로를 통제하기 위해 항상 명상과 절제를 실천한다.\n",
      "\n",
      "### 외형  \n",
      "어깨까지 내려오는 흑갈색 머리카락에 강인한 눈빛. 왼팔에는 드래곤 비늘이 퍼져있듯이 금속같은 푸른 무늬가 피부를 타고 흐른다. 검은 망토와 실용적인 갑옷을 착용.\n",
      "\n",
      "### 무기  \n",
      "**파프니르의 송곳니**  \n",
      "자신이 발견한 금속으로 단련한 길고 곧은 한손검. 검의 칼날에는 비늘 무늬가 새겨져 있고, 공명할 때마다 청록색의 빛이 흐른다.\n",
      "\n",
      "---\n",
      "\n",
      "### 고유 능력  \n",
      "**탐욕의 심연(Deep Greed)**\n",
      "  \n",
      "- 파프니르의 잔재와 연결된 에이라는 상대방의 \"탐욕\"이나 \"욕망\"을 감지하고, 일시적으로 그 힘이나 능력을 \"흡수\"할 수 있다.  \n",
      "- 검이 상대에게 상처를 입힐 때, 적의 강한 의지/욕망이 깃든 능력의 일부를 자신의 힘으로 덧입을 수 있다. 그러나 너무 많은 힘을 흡수하면 파프니르의 저주가 깨어나 자신 역시 괴물로 변질될 위험이 있다.\n",
      "- 이 능력은 순간적으로 상대와의 \"욕망의 충돌\"을 일으키며, 상대가 숨기고 있는 진짜 욕구가 잠시 표면화된다.\n",
      "\n",
      "**예시**  \n",
      "- 불에 대한 탐욕이 강한 적을 베면, 잠시 에이라의 검에서 불을 다루는 힘이 발현된다.\n",
      "- 상대의 무력함을 극복하려는 욕망이 크다면, 그 순간 자신의 신체 능력이 강화된다.\n",
      "\n",
      "> \"진정한 검은 상대의 마음을 꿰뚫는다. 그 끝에는 나 역시 두려워해야 할 나의 그림자가 있음을 잊지 않을 것이다.\"\n",
      "\n",
      "---\n",
      "\n",
      "마음에 드는 설정이길 바라! 더 추가하고 싶은 부분이나 궁금한 점 있으면 말해줘.\n"
     ]
    }
   ],
   "source": [
    "response = client.responses.create(\n",
    "    model='gpt-4.1',\n",
    "    input=[\n",
    "        {\n",
    "            'role':'developer',\n",
    "            'content': '신화나 이야기에서 비롯된 능력을 지닌 가상의 캐릭터의 자세한 설정을 짜는것을 좋아해'\n",
    "        },\n",
    "        {\n",
    "            'role': 'user',\n",
    "            'content': '검사 캐릭터와 그 캐릭터의 고유 능력 하나를 파프니르와 관련해서 설정해줘'\n",
    "        }\n",
    "        ]  \n",
    ")\n",
    "print(response.output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0a7bf79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "completion = client.chat.completions.create(\n",
    "    model='gpt-4.1',\n",
    "    messages=[\n",
    "        {\n",
    "            'role': 'user',\n",
    "            'content': '검사가 지닌 늑대 형태 번개 정령의 능력을 따올만한 신화를 추천해줘'\n",
    "        }\n",
    "    ]\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b6fc497b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"늑대 형태와 번개/천둥 정령의 능력을 조합하려면, 다양한 문화의 신화에서 영감을 받을 수 있습니다. 아래에 몇 가지 관련 신화와 이야기 소재를 추천합니다.\\n\\n### 1. **노르드 신화 – 페나리스 울프(Fenrir) & 토르(Thor)**\\n- **페나리스 울프**는 세계를 삼킬 거대한 늑대로, 파괴적이고 강력한 존재입니다. **토르**는 천둥과 번개의 신이죠. 둘을 결합해 번개와 늑대의 힘을 가진 정령/존재로 재해석할 수 있습니다.\\n- 예: “Fenrithor” 혹은 페나리르의 후손으로 번개를 다루는 늑대 정령.\\n\\n### 2. **북미 원주민 신화 – 썬더버드 & 늑대 토템**\\n- **썬더버드(Thunderbird)**는 번개와 천둥을 일으키는 거대한 새이지만, 북미 원주민 신화에는 늑대도 중요한 토템 동물로 자주 나타납니다.\\n- 예: 늑대와 썬더버드의 혼혈, 혹은 늑대의 모습으로 번개를 다루는 정령.\\n- 일부 부족 이야기에선 동물이 번개의 영혼(스피릿)과 하나가 되어 힘을 쓰는 이야기가 있습니다.\\n\\n### 3. **슬라브 신화 – 페룬(Perun)**\\n- **페룬**은 천둥과 번개의 신으로, 종종 늑대 혹은 곰과 연관짓기도 합니다. 페룬의 사자인 늑대가 번개 힘을 지닌 신의 대리인으로 등장할 수 있습니다.\\n\\n### 4. **일본 신화 – 라이진(Raijin)과 오오카미**\\n- **라이진**은 번개와 천둥의 신, **오오카미**는 늑대 신입니다. 두 신의 속성을 합쳐 '라이진의 화신'으로 늑대 형태를 가진 번개 정령을 만들 수도 있습니다.\\n\\n### 5. **중국 신화 – 뇌공(雷公)**\\n- **뇌공**은 번개/천둥의 신입니다. 동양 신화에서는 동물 형태로 신령이 나타나는 경우가 흔해서, 뇌공의 능력을 지닌 ‘늑대귀신’ 형태로 차용 가능!\\n\\n---\\n\\n### 참고할 만한 조합 및 설정 예시\\n\\n- **하늘을 달리는 늑대 정령**: 유성처럼 빠르게 움직이며 번개처럼 강렬한 힘을 씀. 화가 나면 번개를 내리치거나, 울부짖음으로 천둥을 부름.\\n- **바람과 번개의 수호자**: 무리를 수호하면서 적을 번개로 공격하는 신성한 늑대 영혼.\\n- **초월적 존재의 사자**: 번개 신(예: 페룬, 토르, 라이진 등)의 명을 받아 움직이는 늑대 모습의 정령.\\n\\n---\\n\\n더 구체적으로 해당 신화 속 설화나 이름이 궁금하시면 추가로 알려드리겠습니다!\""
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(completion.choices[0])\n",
    "completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "840551aa",
   "metadata": {},
   "source": [
    "## 사용자 입력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "93972b46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'미니언즈(Minions)는 일루미네이션 엔터테인먼트(Illumination Entertainment)에서 제작한 애니메이션 영화 시리즈 <슈퍼배드(Despicable Me)>와 그 스핀오프 영화에 등장하는 노란색 캐릭터들입니다. 아래에 미니언즈에 대한 주요 정보를 정리해 드릴게요.\\n\\n### 개요\\n\\n- **최초 등장:** 2010년 <슈퍼배드(Despicable Me)>\\n- **소속:** 주인공 그루(Gru)의 충직한 하수인들\\n- **색깔:** 노란색\\n- **키:** 크기가 다소 다르지만 대부분 작고 통통한 체형\\n- **눈:** 한 개 또는 두 개\\n- **복장:** 파란색 멜빵 바지와 검정 장갑, 구글(보호안경)을 착용\\n- **언어:** ‘미니언어(Minionese)’라는 독특한 언어(여러 외국어, 동음이의, 의성어가 섞여 있음)를 사용\\n\\n### 특징\\n\\n- **성격:** 천진난만하고 장난기가 많으며, 종종 엉뚱하고 실수를 많이 하지만, 엄청난 충성심을 가지고 있음\\n- **특기:** 어리바리해 보여도 의외로 뛰어난 기술력(기계 조작, 발명 등)\\n- **목적:** ‘가장 사악한 주인’을 찾아 모시고 모험을 즐기는 것이 인생의 목표\\n- **음식:** 바나나를 아주 좋아함\\n\\n### 영화 시리즈\\n\\n1. **슈퍼배드(Despicable Me, 2010)**\\n2. **슈퍼배드 2(Despicable Me 2, 2013)**\\n3. **미니언즈(Minions, 2015)**\\n   - 미니언즈들만 주인공인 스핀오프 영화. 그들의 기원과 과거를 다룸.  \\n4. **슈퍼배드 3(Despicable Me 3, 2017)**\\n5. **미니언즈 2: 더 라이즈 오브 그루(Minions: The Rise of Gru, 2022)**\\n   - 젊은 그루와 미니언즈의 이야기를 다룸.\\n\\n### 인기도\\n\\n미니언즈는 전 세계적으로 인기를 얻은 캐릭터로, 애니메이션 분야에서 대표적인 ‘귀여운 악당 조력자’ 이미지입니다. 캐릭터 상품(완구, 인형, 잡화 등)도 엄청나게 출시되었고, SNS에서 밈(meme)으로도 자주 쓰입니다.\\n\\n### 기타\\n\\n- 미니언즈의 독특한 언어와 엉뚱한 행동은 어린이 뿐 아니라 성인들에게도 큰 웃음을 줍니다.\\n- 미니언즈 더빙에는 제작진들이 직접 참여하여 목소리를 냅니다.\\n- 미니언즈의 이름은 케빈, 스튜어트, 밥 등이 대표적입니다.\\n\\n궁금한 점이 더 있으면 말씀해주세요!'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "\n",
    "user_input = input('type your question: ')\n",
    "\n",
    "client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "\n",
    "response = client.responses.create(\n",
    "    model='gpt-4.1',\n",
    "    input=user_input\n",
    ")\n",
    "\n",
    "response.output_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "561f5135",
   "metadata": {},
   "source": [
    "## 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "70405653",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def get_weather(latitude, longitude):\n",
    "    response = requests.get(f\"https://api.open-meteo.com/v1/forecast?latitude={latitude}&longitude={longitude}&current=temperature_2m,wind_speed_10m&hourly=temperature_2m,relative_humidity_2m,wind_speed_10m\")\n",
    "    data = response.json()\n",
    "    return data['current']['temperature_2m']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "68eab5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [{\n",
    "    \"type\": \"function\",\n",
    "    \"name\": \"get_weather\",\n",
    "    \"description\": \"Get current temperature for provided coordinates in celsius.\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"latitude\": {\"type\": \"number\"},\n",
    "            \"longitude\": {\"type\": \"number\"}\n",
    "        },\n",
    "    \"required\": [\"latitude\", \"longitude\"],\n",
    "    \"additionalProperties\": False\n",
    "    },\n",
    "    \"strict\": True\n",
    "}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4758d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_message = [{'role': 'user', 'content': '파리 날씨 어때?'}]\n",
    "\n",
    "# 함수 호출 기능\n",
    "response = client.responses.create(\n",
    "    model='gpt-4.1',\n",
    "    input=input_message,\n",
    "    tools=tools\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "57617527",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'arguments': '{\"latitude\":48.8566,\"longitude\":2.3522}',\n",
       " 'call_id': 'call_3wfJj5TN0lgQ3m8yT7X7ysEl',\n",
       " 'name': 'get_weather',\n",
       " 'type': 'function_call',\n",
       " 'id': 'fc_685bae75bf54819a90b6de2e5d87b84b06999eb09654d77f',\n",
       " 'status': 'completed'}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(response.output[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "dc1781d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current temperature in Paris: 23.3°C\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "tool_call = response.output[0]\n",
    "args = json.loads(tool_call.arguments)\n",
    "result = get_weather(args['latitude'], args['longitude'])\n",
    "print(f\"Current temperature in Paris: {result}°C\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1988eeed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재 파리의 온도는 약 23.3℃입니다. 맑고 쾌적한 날씨일 가능성이 높아요!\n"
     ]
    }
   ],
   "source": [
    "input_message.append(tool_call)\n",
    "\n",
    "\n",
    "input_message.append({\n",
    "    'type': 'function_call_output',\n",
    "    'call_id': tool_call.call_id,\n",
    "    'output': str(result)\n",
    "})\n",
    "\n",
    "\n",
    "\n",
    "# 최종 응답\n",
    "response2= client.responses.create(\n",
    "    model='gpt-4.1',\n",
    "    input=input_message,\n",
    "    tools=tools\n",
    ")\n",
    "\n",
    "print(response2.output_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
